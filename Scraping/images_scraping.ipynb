{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monumen Nasional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Kota Tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dunia Fantasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taman Mini Indonesia Indah (TMII)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Atlantis Water Adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Place_Id                         Place_Name\n",
       "0         1                   Monumen Nasional\n",
       "1         2                           Kota Tua\n",
       "2         3                      Dunia Fantasi\n",
       "3         4  Taman Mini Indonesia Indah (TMII)\n",
       "4         5           Atlantis Water Adventure"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tourism_name.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 437 tourist attraction names in the dataset:\n",
      "1. Monumen Nasional\n",
      "2. Kota Tua\n",
      "3. Dunia Fantasi\n",
      "...\n",
      "435. Taman Air Mancur Menari Kenjeran\n",
      "436. Taman Flora Bratang Surabaya\n",
      "437. Gereja Perawan Maria Tak Berdosa Surabaya\n"
     ]
    }
   ],
   "source": [
    "keywords = df['Place_Name'].copy().tolist()\n",
    "keywords_len = len(keywords)\n",
    "\n",
    "print(f'There are {keywords_len} tourist attraction names in the dataset:')\n",
    "\n",
    "for idx, place_name in enumerate(keywords[:3]):\n",
    "    print(f'{idx + 1}. {place_name}')\n",
    "print('...')\n",
    "for idx, place_name in enumerate(keywords[-3:]):\n",
    "    print(f'{keywords_len-2 + idx}. {place_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_images(keyword: str, num:int, driver: webdriver) -> None:\n",
    "    \"\"\"\n",
    "    Scrapes images based on the given keyword.\n",
    "\n",
    "    Args:\n",
    "        keyword (str): The search term used to find images.\n",
    "        num (int): The number of images to scrape and download.\n",
    "        driver (webdriver): The Selenium WebDriver instance used for browsing.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Directories:\n",
    "        - `images_output/<keyword>`: Stores downloaded images.\n",
    "        - `csv_output`: Stores CSV files with metadata for scraped images.\n",
    "\n",
    "    Output:\n",
    "        - Downloads up to `num` images to the `images_output/<keyword>` directory.\n",
    "        - Saves a CSV file containing image metadata in the `csv_output` directory.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Make sure the keyword name does not contain the \"\\\" or \"/\" signs.\n",
    "    keyword = keyword.replace('\\\\', ' ').replace('/', ' ')\n",
    "    \n",
    "    img_xpath = '/html/body/div[11]/div[2]/div[3]/div/div/c-wiz/div/div[2]/div[2]/div/div[2]/c-wiz/div/div[3]/div[1]/a/img[1]'\n",
    "    search_url = f\"https://www.google.com/search?tbm=isch&q={keyword}\"\n",
    "    img_output_dir = 'images_output'\n",
    "    csv_output_dir = 'csv_output'\n",
    "    data = list()\n",
    "    counter = 0\n",
    "\n",
    "    if not os.path.exists(csv_output_dir):\n",
    "        os.makedirs(csv_output_dir)\n",
    "    if not os.path.exists(img_output_dir):\n",
    "        os.makedirs(img_output_dir)\n",
    "    if not os.path.exists(os.path.join(img_output_dir, keyword)):\n",
    "        os.makedirs(os.path.join(img_output_dir, keyword))\n",
    "    \n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    imgs_pointer = driver.find_elements(By.CSS_SELECTOR,'div.F0uyec')\n",
    "    \n",
    "    for img_button in imgs_pointer:\n",
    "        \n",
    "        # If the number of image requests is met, then stop.\n",
    "        if len(data) == num:\n",
    "            break\n",
    "\n",
    "        # Click and display the original image.\n",
    "        driver.execute_script(\"arguments[0].click();\", img_button)\n",
    "\n",
    "        # Give 2 chances to get the original image link,\n",
    "        # rather than the cached version of the image.\n",
    "        for _ in range(2):\n",
    "            time.sleep(2)\n",
    "            img_link = driver.find_element(By.XPATH, img_xpath).get_attribute('src')\n",
    "            cached_img = img_link.startswith('https://encrypted-tbn0.gstatic.com/')\n",
    "            jpg_png = re.search(r'\\.(jpg|png).*$', img_link)\n",
    "            if not cached_img and jpg_png:\n",
    "                break\n",
    "        \n",
    "        # If still only get the cache image, then get another image.\n",
    "        if cached_img or not jpg_png:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Try downloading the image\n",
    "            img_data = requests.get(img_link).content\n",
    "            img_path = os.path.join(img_output_dir, keyword, f'{keyword}_{counter}.{jpg_png[1]}')\n",
    "            with open(img_path, 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "        # Append the link to data\n",
    "        data.append({\n",
    "            'keyword': keyword,\n",
    "            'link': img_link\n",
    "        })\n",
    "\n",
    "        print('  ' + img_link)\n",
    "        counter += 1\n",
    "\n",
    "    # Save all the links to CSV file\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    csv_path = os.path.join(csv_output_dir, f'{keyword}.csv')\n",
    "    temp_df.to_csv(csv_path, index=False)\n",
    "    print(f\"  Successfully downloaded {len(data)} {keyword} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 437 tourist attractions will be scraped\n"
     ]
    }
   ],
   "source": [
    "# If an error occurs during the scraping process,\n",
    "# please replace the `start_idx`` number with the last\n",
    "# index number of the tourist attraction being scraped\n",
    "start_idx = 0\n",
    "keywords_start = keywords[start_idx:]\n",
    "print(f'A total of {len(keywords_start)} tourist attractions will be scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Scraping Monumen Nasional images\n",
      "  https://upload.wikimedia.org/wikipedia/id/thumb/b/b1/Merdeka_Square_Monas_02.jpg/800px-Merdeka_Square_Monas_02.jpg\n",
      "  https://dynamic-media-cdn.tripadvisor.com/media/photo-o/15/c3/d2/54/jakarta-amazing-tour.jpg?w=800&h=500&s=1\n",
      "  https://cozzy.id/uploads/0000/630/2024/09/04/cozzyid-hotel-murah-hotel-terdekat-penginapan-murah-penginapan-terdekat-booking-hotel-monumen-nasional-monas-ikon-jakarta-yang-membanggakan-sumber-gambar-kompas.jpg\n",
      "  Successfully downloaded 3 Monumen Nasional images\n",
      "1 : Scraping Kota Tua images\n",
      "  https://upload.wikimedia.org/wikipedia/commons/e/ee/Fatahillah.jpg\n",
      "  https://dynamic-media-cdn.tripadvisor.com/media/photo-o/14/fc/01/83/wisata-kota-tua-mel-s.jpg?w=900&h=-1&s=1\n",
      "  https://asset.kompas.com/crops/XK3vTK30F0d4NLCQ5oIMEGs9oMk=/0x0:1800x1200/1200x800/data/photo/2021/11/11/618cb2bd3245b.jpg\n",
      "  Successfully downloaded 3 Kota Tua images\n",
      "2 : Scraping Dunia Fantasi images\n",
      "  https://s-light.tiket.photos/t/01E25EBZS3W0FY9GTG6C42E1SE/rsfit19201280gsm/events/2021/12/08/9c6ae660-1799-4276-b81d-f8b0b85669d6-1638949473006-1e6c55a1b1edca6bf250012af2cc79e2.jpg\n",
      "  https://storage.jakarta-tourism.go.id/public/articles/xhBtnBO7Lmm5uLBl3EcmcZBFApjMyo-metaRHVmYW4gQkcucG5n-.png\n",
      "  https://res.klook.com/images/fl_lossy.progressive,q_65/c_fill,w_1295,h_863/w_80,x_15,y_15,g_south_west,l_Klook_water_br_trans_yhcmh3/activities/x5fzlp6mfnl6n6qlyfkh/[LewatiAntrean]TiketDufan(DuniaFantasiAncol)diJakarta.jpg\n",
      "  Successfully downloaded 3 Dunia Fantasi images\n",
      "3 : Scraping Taman Mini Indonesia Indah (TMII) images\n",
      "  https://tamanmini.com/taman_jelajah_indonesia/wp-content/uploads/2023/07/1689234443714-scaled-1500x1000.jpg\n",
      "  https://tamanmini.com/taman_jelajah_indonesia/wp-content/uploads/2023/07/banner-4.jpg\n",
      "  https://tamanmini.com/taman_jelajah_indonesia/wp-content/uploads/2023/07/1689234443735-scaled-1500x1000.jpg\n",
      "  Successfully downloaded 3 Taman Mini Indonesia Indah (TMII) images\n",
      "4 : Scraping Atlantis Water Adventure images\n",
      "  https://s-light.tiket.photos/t/01E25EBZS3W0FY9GTG6C42E1SE/rsfit19201280gsm/events/2022/02/07/5035c159-00c7-496a-a948-a954f2c0b1a9-1644230114996-1bb3436e799ef18dbd9b35c55e577e74.jpg\n",
      "  https://res.klook.com/images/fl_lossy.progressive,q_65/c_fill,w_1200,h_630/w_80,x_15,y_15,g_south_west,l_Klook_water_br_trans_yhcmh3/activities/wbmh43n6r08ibwwtofrm/Tiket%20Atlantis%20Water%20Adventures%20di%20Jakarta.jpg\n",
      "  https://www.ancol.com/shared/images/5d3f526e-5729-4af1-8d31-5072bd832270.png\n",
      "  Successfully downloaded 3 Atlantis Water Adventure images\n"
     ]
    }
   ],
   "source": [
    "num_of_image = 3\n",
    "driver = webdriver.Firefox()\n",
    "driver.get('https://google.com')\n",
    "    \n",
    "# Running the seach function through the all keywords\n",
    "for index, keyword in enumerate(keywords_start):\n",
    "    print(f\"{index + start_idx} : Scraping {keyword} images\")\n",
    "    search_images(keyword=keyword, num=num_of_image, driver=driver)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
